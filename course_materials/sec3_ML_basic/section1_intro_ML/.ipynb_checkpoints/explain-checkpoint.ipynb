{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 機械学習概論\n",
    "機械学習によって解決される問題には，未知のデータの予測やデータの分類など様々なものがあります．\n",
    "「どのように予測するか」，「どのように分類するか」といった問い達に対して，機械学習ではデータをたくさん用意してデータのパターンを分析することによって解答を与えます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教師あり学習と教師なし学習\n",
    "機械学習の手法は大きく3つに分けられます．<br>\n",
    "* 教師あり学習：データの傾向から，未知のデータを予測する．\n",
    "* 教師なし学習：データの構造を見つけ出す．\n",
    "* 強化学習：試行錯誤をくり返し，より良い行動を学習する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教師あり学習\n",
    "次のような問題を考えてみましょう．<br>\n",
    "<br>\n",
    "『過去の顧客について年令，性別，商品を購入したかについて集計したデータがある．<br>\n",
    "どのような年令，性別の人が商品を買ってくれるのか，傾向を分析し，新規の顧客が商品を買うかどうか予測を行いたい．』<br>\n",
    "<br>\n",
    "この問題のように，データの傾向から，未知のデータを正確に予測を行うことを目指す機械学習の手法を教師あり学習と言います．<br>\n",
    "<br>\n",
    "予測される対象を表す変数(今回は商品を購入したか)を目的変数，予測のために用いられる変数(今回は年令)を説明変数と言います．<br>\n",
    "教師あり学習は，目的変数が量的か質的かで扱い方が異なります．量的のときは回帰問題，質的変数のときは分類問題と呼ばれます．<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教師なし学習\n",
    "一方で，変数の値の予測を目的としない機械学習の手法も存在します．<br>\n",
    "次のような問題を考えてみましょう．<br>\n",
    "<br>\n",
    "『ある学校では，数学の授業のクラス編成を考えている．各生徒の成績のデータをもとに，似たタイプの生徒を同じクラスに集めることで，授業の効果を高めたい．どの生徒を同じクラスに配置するべきか？』<br>\n",
    "<br>\n",
    "この問題では予測したい変数はなく，どの生徒が似ているか？という構造を問題にしています．<br>\n",
    "これは教師なし学習の一つでクラスタリングと呼ばれる問題です．<br>\n",
    "教師なし学習が扱う問題は他に次元圧縮などがあります．<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **次元削減**：類似した変数をまとめる。\n",
    "<center><img src = \"dim_reduction.png\" style=\"width:500px\"></center>\n",
    "* **クラスタリング**：類似したデータポイントをまとめる。\n",
    "<center><img src = \"clustering.png\" style=\"width:500px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノーフリーランチ定理\n",
    "最初に機械学習の一般論として極めて重要な定理を紹介しておきましょう。\n",
    "\n",
    "**定理** どんなタスクに対しても万能な学習アルゴリズムは存在しない。\n",
    "\n",
    "この定理を**ノー・フリーランチ定理**と言います。要は、タスクに応じて手法には適材適所があるのです。実際にタスクを解決する際には複数のアルゴリズムを勉強して試し、もっとも性能の良いモデルを選ぶことが重要です。例えば、以下の図は分類問題とそれに対する様々な学習アルゴリズムです。\n",
    "\n",
    "<center><img src = \"classification_plot.png\" style=\"width:800px;\"></center>\n",
    "\n",
    "また、その時々で最も性能の良いモデルを選ぶためには、適切な**モデル評価**と**モデル選択**の方法を学ぶことが重要です。以下では、教師あり学習におけるモデル評価とモデル選択について概要を紹介しましょう。\n",
    "\n",
    "### 過剰適合と過少適合\n",
    "ひとまず、以下の実験を見てみましょう。\n",
    "<center><img src = \"overfit.png\" style=\"width:300px;\"></center>\n",
    "実際には、３次式にノイズがついて発生した10個のデータであるにも関わらず、９次式の仮説を当てはめてしまったがために、手持ちのデータの上では損失が0になってしまっている様子です。教師あり学習の本来の意義は**未知のデータに対する予測**でしたが、これでは新しいデータに対しては予測の精度は悪くなってしまいます。\n",
    "\n",
    "このように本来のデータの発生メカニズム（確率分布と言います）に比して複雑すぎる仮説を立ててしまうと、学習に用いたデータでの損失が小さいにも関わらず、未知のデータに対する損失が大きいという現象が起こることがあります。これを**過剰適合**と言います。\n",
    "\n",
    "**演習**　一方で、逆に本来のデータの発生メカニズムやサンプルサイズに比して単純すぎる仮説を立ててしまうことにより、手持ちのデータに対する損失が小さくならないことがあります。これを**過少適合**と言います。\n",
    "1. 過少適合が起こっているような状況を、過剰適合の時のようにグラフに表してください。\n",
    "2. 過少適合は他に要因によっても起こりうることがあります。考えてみてください。\n",
    "\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n",
    "\n",
    "### モデル評価\n",
    "過剰適合を勉強するなかでわかることは、学習時に損失が小さいモデルであっても、決して未知のデータに対して良い予測を返すとは限らないということです。また、そもそも学習時の損失が小さい場合も過少適合しているリスクがあるということを学びました。そこで、モデルを評価する場合には手元のデータを\n",
    "* **訓練データ**：モデルの学習に用いるデータ\n",
    "* **テストデータ**：学習したモデルの精度を評価するためのデータ\n",
    "\n",
    "に分割し、それぞれでの精度をチェックすることが重要だとわかります。これは大雑把にいうと2種類の手法があり\n",
    "* **hold-out検証**：以下のようにデータを分割し、１回精度を計算する。\n",
    "<center><img src = \"holdout.png\" style=\"width:300px;\"></center>\n",
    "* **交差検証法**：以下のようにデータをK分割し、K回精度を計算する。例えば、下の図は5-fold cross validationと言われる手法です。\n",
    "<center><img src = \"crossval.png\" style=\"width:500px;\"></center>\n",
    "\n",
    "が知られています。\n",
    "\n",
    "**演習** hold-out検証・交差検証法のメリット・デメリットを挙げてください。<br>\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n",
    "||<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習を支える数学\n",
    "機械学習の理論的な背景には様々な数学が用いられています．中でも重要なものは微積分，線形代数，確率統計です．<br>\n",
    "<br>\n",
    "微分法を応用することで関数の増減の様子を捉えることができます．機械学習の学習のほとんどが「何らかの基準で最も良い式を求める」という形で定式化されます．これは「何らかの基準」を数式として表現することによって関数の最大値や最小値を求める問題と考えることができます．関数の増減を調べることで，このような最大最小問題を解くことができます．<br>\n",
    "また，積分法は確率の計算をするために不可欠です．<br>\n",
    "<br>\n",
    "線型代数はたくさんの変数とたくさんの式を一手に扱い，複雑な計算を進めていくために非常に強力な道具です．機械学習ではときには100をこえるようなたくさんの変数を扱います．また複数の式を同時に扱うような手法も存在します．線形代数によってこのような大規模な数式をコンパクトに扱えるだけでなく，数式たちを分析していく上で非常に強力な道具です．<br>\n",
    "<br>\n",
    "確率統計の理論を用いて，データの重要な特徴(中心がどこにあるか，散らばりはどうか，異なるデータ間の関係性等)を調べることができます．機械学習の手法の有効性を理論的に評価するためにも，確率統計の知識は重要です．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
