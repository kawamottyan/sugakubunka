{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2　Newtonブースティング法の考え方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**abstract** : Newtonブースティング法は、教師あり学習が仮説空間に対する損失関数の最小化問題であることに注目し、数理最適化の手法であるNewton法を関数空間に拡張することで最適な仮説を導く方法を提案したものです。このことを理解するために、\n",
    "\n",
    "A. Newton法の仕組み<br/>\n",
    "B. Newtonブースティング法の仕組み\n",
    "\n",
    "を説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Newton法の仕組み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newton法とそのalgorithm** : $d$個の実数からなるベクトルの全体$\\mathbb{R}^d$を定義域に持つような関数$L(x)$の最適解の値を計算したいとします。要するに、\\begin{eqnarray*}x^*=\\mathrm{argmax}_{x}L(x)\\end{eqnarray*}を考えているわけです。特に、関数$L(x)$が2階微分可能、要するに\n",
    "* 1階導関数$\\nabla_x L(x)$を持ち、この導関数に$x=a$を代入した値$\\nabla_x L(a)$を計算できる。\n",
    "* 2階導関数$\\nabla^2_x L(x)$を持ち、この導関数に$x=a$を代入した値$\\nabla^2_x L(a)$を計算できる。\n",
    "\n",
    "このとき、以下のようなalgorithmが用いられることがあります。\n",
    "\n",
    "**Input** : \n",
    "* $x_0$ : 初期値\n",
    "* $\\eta$ : 学習率\n",
    "* $M$ : 繰り返しの最大数\n",
    "* $\\nabla_x L$ : 関数$L$の1階導関数\n",
    "* $\\nabla^2_x L$ : 関数$L$の2階導関数\n",
    "\n",
    "**Process** :\n",
    "1. $a\\leftarrow x_0$　　# 解の初期値\n",
    "2. for $i$ in $1,\\cdots,M$:\n",
    "3. 　　$a \\leftarrow a – \\eta \\nabla^2_x L(a)^{-1}\\nabla_x L(a)$\n",
    "4. return $a$\n",
    "\n",
    "これを**Newton法**といいます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newton法のアイディア** : Newton法のalgorithmは、目的関数を2次近似することで現在の点から停留点に向かう方向を求め、その方向$\\nabla^2_x L(a)^{-1}\\nabla_x L(a)$に移動するという計算を繰り返すという流れを実装しています。このことを実際に1変数の目的関数の場合で確認してみましょう。\n",
    "\n",
    "<center><img src=\"./imgs/newton.png\" width=500px><br>Newton法の仕組み</center>\n",
    "\n",
    "関数$L(x)$を現在の解$x=a$まわりで2次までTaylor展開することで、関数の2次近似$\\tilde{L}(x)$を次のように得ます。\\begin{eqnarray*}\\tilde{L}(x)=L(a)+\\nabla_xL(a)(x-a)+\\frac{1}{2}\\nabla^2_xL(a)(x-a)^2\\end{eqnarray*}この式を微分すると\\begin{eqnarray*}\\nabla_x \\tilde{L}(x)=\\nabla_xL(a)+\\nabla^2_xL(a)(x-a)\\end{eqnarray*}が得られます。あとは、求めたい$\\nabla_xL(x)=0$の代わりに$\\nabla_x\\tilde{L}(x)=0$の解$\\hat{a}$を求めると、右辺から$\\hat{a}=a-\\nabla^2_x L(a)^{-1}\\nabla_x L(a)$を得ることが出来ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Newtonブースティング法の仕組み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newtonブースティング法は、Newton法を実数ベクトルを入力にとる目的関数の最適化から、**仮説を入力にとる目的関数の最適化に拡張したもの**です。拡張の流れから説明するとやや難しいので、ここでは、Newtonブースティング法のalgorithmを天下りに説明して、紹介したalgorithmがなぜNewton法の拡張とみなせるのかという流れで説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B1. Newtonブースティング法のalgorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**教師あり学習における最適化問題の復習** : 教師あり学習における最適化問題とは、事前にデータ$\\mathcal{D}=\\{(x_1,y_1),\\cdots,(x_n,y_n)\\}$を準備し、\n",
    "1. 仮説空間$\\mathcal{H}$\n",
    "2. 損失関数$l(\\hat{y_i},y)$\n",
    "\n",
    "を定義したうえで、以下のような問題を解くことを言うのでした。\\begin{eqnarray*}\\hat{h}(x)&=&\\mathrm{argmin}_{h\\in\\mathcal{H}}L(h)\\\\\n",
    "\\text{ where }L(h)&=&\\sum_{i=1}^{n}l(h(x_i),y_i)\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newtonブースティング法のalgorithm例** : 特に、仮説空間$\\mathcal{H}$を決定木の仮説の和\n",
    "\\begin{eqnarray*}\n",
    "h(x) &=& \\sum_{i=0}^{M}h_{i}(x)\n",
    "\\end{eqnarray*}\n",
    "の全体で定義します。また簡単のために、損失関数を2乗損失$l(\\hat{y},y)=(\\hat{y}-y)^2$にします。Newtonブースティング法では、教師あり学習における最適化問題に対して、この$h_{i}(x)$を以下のalgorithmに従って求めます。\n",
    "\n",
    "**Input** :\n",
    "* $\\eta>0$ : 学習率\n",
    "* $\\nabla_h L$ : 目的関数$L$の1階導関数\n",
    "* $\\nabla^2_h L$ : 目的関数$L$の2階導関数\n",
    "* $M$ : 繰り返しの最大回数\n",
    "\n",
    "**Process** :\n",
    "1. $\\hat{h}(x)\\leftarrow \\bar{y}$\n",
    "2. for $t$ in $1,\\cdots,M$:\n",
    "3. 　　残差$r_i=y_i-h(x_i)$, $i=1,\\cdots,n$を計算する。\n",
    "4. 　　$\\mathcal{D}':=\\{(x_1,-r_1),\\cdots,(x_n,-r_n)\\}$で$h_{t}(x)$を学習する。\n",
    "5. 　　$\\hat{h}(x)\\leftarrow\\hat{h}(x)+\\eta h_{t}(x)$\n",
    "6. return $\\hat{h}(x)$\n",
    "\n",
    "4行目で求めた$h_{t}(x)$によって、求める仮説$\\hat{h}(x)$を$\\eta h_t(x)$だけ更新することが、「仮説$h(x)$を入力にとる目的関数$L(h)$にNewton法を行う」ことに対応しています。\n",
    "\n",
    "**[Remark]**  仮説空間を決定木の仮説の和の全体で定義することはalgorithmを導出のなかでは本質的ではありませんが、Newtonブースティング法の仮説空間としてこれを採用することが一般的なので、ここではそう設定しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B2. Newton法の拡張になっていることの説明（難）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2次近似の導入** : 上記のalgorithmに対して、$t$回目の繰り返しで得られる仮説を$\\hat{h}^{(t)}(x)$と書くことにします。目的関数$L(h)$は、関数$\\hat{h}^{(t)}(x)$を中心に次のように近似することが出来ます。\n",
    "\\begin{eqnarray*}\n",
    "\\tilde{L}(h) &=& L(h^{(t)}) + \\sum_{i=1}^{n} \\left\\{\\frac{\\partial l}{\\partial\\hat{y}}(h^{(t)}(x_i),y_i)(h(x_i)-h^{(t)}(x_i)) + \\frac{1}{2}\\frac{\\partial^2 l}{\\partial\\hat{y}^2}(h^{(t)}(x_i),y_i)(h(x_i)-h^{(t)}(x_i))^2\\right\\}\n",
    "\\end{eqnarray*}\n",
    "これを目的関数の2次近似と言います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2次近似をどう導出したか** : ここで、\n",
    "\\begin{eqnarray*}\n",
    "\\langle F, G\\rangle &:=& \\sum_{i=1}^nF(x_i)G(x_i)\n",
    "\\end{eqnarray*}\n",
    "と定義します。また、現在の仮説を$h^{(t)}(x)$と書くことにします。目的関数$L(h)$の2次近似をTaylor展開のアナロジーで考えて、\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\tilde{L}(h) &:=& L(\\hat{h}^{(t)}) + \\langle\\nabla_hL(\\hat{h}^{(t)}), h-\\hat{h}^{(t)}\\rangle + \\frac{1}{2} \\langle\\nabla^2_hL(\\hat{h}^{(t)}), (h-\\hat{h}^{(t)})^2\\rangle\n",
    "\\end{eqnarray*}\n",
    "\n",
    "と表現することにしましょう。このとき、1階導関数・2階導関数はそれぞれ\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\nabla_{h}L(\\hat{h}^{(t)})(a) &=& \\begin{cases}\\frac{\\partial l}{\\partial\\hat{y}}(\\hat{h}^{(t)}(x_i),y_i)\\text{ if } a=x_i\\\\0\\text{ otherwise}\\end{cases}\\\\\n",
    "\\nabla^2_{h}L(\\hat{h}^{(t)})(a) &=& \\begin{cases}\\frac{\\partial^2 l}{\\partial\\hat{y}^2}(\\hat{h}^{(t)}(x_i),y_i)\\text{ if }a=x_i\\\\0\\text{ otherwise}\\end{cases}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "なので、\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\tilde{L}(h) &=& L(\\hat{h}^{(t)}) + \\sum_{i=1}^{n} \\left\\{\\frac{\\partial l}{\\partial\\hat{y}}(\\hat{h}^{(t)}(x_i),y_i)(h(x_i)-\\hat{h}^{(t)}(x_i)) + \\frac{1}{2}\\frac{\\partial^2 l}{\\partial\\hat{y}^2}(\\hat{h}^{(t)}(x_i),y_i)(h(x_i)-\\hat{h}^{(t)}(x_i))^2\\right\\}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "が従います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**algorithmの導出** : 上のalgorithmにおける仮説の更新分$h_t(x)$は、2次近似の$h(x)-\\hat{h}^{(t)}(x)$に対応しています。要するに$h(x):=h(x)-\\hat{h}^{(t)}(x)$です。また、損失関数が2乗損失$l(\\hat{y},y)=(\\hat{y}-y)^2$ならば、\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\nabla_{h}L(\\hat{h}^{(t)})(a) &=& \\begin{cases}2(\\hat{h}^{(t)}-y)\\text{ if } a=x_i\\\\0\\text{ otherwise}\\end{cases}\\\\\n",
    "\\nabla^2_{h}L(\\hat{h}^{(t)})(a) &=& \\begin{cases}2\\text{ if }a=x_i\\\\0\\text{ otherwise}\\end{cases}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\n",
    "が従います。これから、目的関数の2次近似$\\tilde{L}(h)$を次のように書き換えられるわけです。\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\tilde{L}(h) &=& L(\\hat{h}^{(t)}(h)) + 2\\sum_{i=1}^{n}(\\hat{h}^{(t)}(x_i)-y_i)h_{t}(x_i) + \\sum_{i=1}^{n}h_{t}(x_i)^2\\\\\n",
    "&=& \\sum_{i=1}^{n}\\left\\{h_{t}(x_i)-(y_i-\\hat{h}^{(t)}(x_i))\\right\\}^2 + \\mathrm{const.}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "これより2次近似が最も小さくなるのは、$h_{t}(x_i)$を$\\mathcal{D}':=\\{(x_1,y_1-\\hat{h}^{(t)}(x_1)),\\cdots,(x_n,y_n-\\hat{h}^{t)}(x_n))\\}$で学習させたときです。この学習を決定木で行えば、上記のalgorithmになります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
