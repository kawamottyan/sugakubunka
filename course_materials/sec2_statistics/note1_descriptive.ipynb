{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1　記述統計学\n",
    "\n",
    "## 1.1　データの分類\n",
    "### 1.1.1　質的変数と量的変数\n",
    "まず、私たちが扱うデータの分類について、いくつかの視点からみておくことにしましょう。身長や体重、年収などのデータのことを統計学では**変数**とよびます。最も重要な分類は、**質的変数**と**量的変数**の区別です。\n",
    "\n",
    "    質的変数 : あるデータがカテゴリーに属することを示すデータ。性別、国\n",
    "    量的変数 : 数字で表現されたデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2　尺度\n",
    "もう少し細かい分類として、尺度と呼ばれる変数の分類法があります。\n",
    "\n",
    "    名義尺度 : あるデータがカテゴリーに属することを示す。\n",
    "    順序尺度 : 順序を持つ。かけっこの順位、「好き、嫌い、普通」といったアンケートの結果\n",
    "    間隔尺度 : 等間隔性をもつ。温度、西暦、テストの点数\n",
    "    比例尺度 : 倍数関係がある。（0であることに意味がある）身長、体重、速度\n",
    "\n",
    "[問題]　各尺度の例を挙げてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[解答]\n",
    "* 名義尺度：性別、出身地　\n",
    "* 順序尺度：順番、アンケートなどの5件法　\n",
    "* 間隔尺度：日付、摂氏温度　\n",
    "* 比例尺度：絶対温度、体重、年収"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3　離散変数と連続変数\n",
    "\n",
    "変数の分類でもう一つ重要なのが、**離散変数**と**連続変数**の区別です。\n",
    "\n",
    "    離散変数 : 整数などのように、飛び飛びの値しか取れない変数。例えばサイコロの目など。\n",
    "    連続変数 : 離散変数とは違い、どこまでも細かく値を取れる変数。（どこまでも細かい値が考えられる）\n",
    "\n",
    "この区別は、後に**確率分布**を考えるときに重要になります。\n",
    "\n",
    "[問題]　離散変数と連続変数の実例を挙げてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[解答]\n",
    "\n",
    "離散変数：サイコロの目、訪問者数\n",
    "\n",
    "連続変数：身長、重さ、年収?(厳密には離散値だが・・・)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##　1.2　基礎統計量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "統計学では、ある変数の様子を様々な数値に要約して表現します。その中でも特に有用なものを**基礎統計量**として定義します。これ以降の数式は、以下のような抽象的なデータ構造を想定していきます。\n",
    "\n",
    "| index | $X$ |$Y$ |\n",
    "|:----------------:|:------------:|:------------:|\n",
    "| 1| $x_1$ |$y_1$ |\n",
    "| 2| $x_2$ | $y_2$ |\n",
    "| 3 | $x_3$| $y_3$|\n",
    "| $\\vdots$| $\\vdots$| $\\vdots$ |\n",
    "| n-1 | $x_{n-1}$ | $y_{n-1}$ |\n",
    "| n | $x_n$ | $y_n$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "height = np.array([170, 172, 180, 165, 177, 162, 159, 172, 168, 162])\n",
    "weight = np.array([55, 65, 65, 59, 68, 44, 57, 70, 59, 55])\n",
    "sex = np.array(['女','男', '男', '女', '男', '女', '女', '男', '女', '女'])\n",
    "\n",
    "sample_df = pd.DataFrame({\n",
    "    'height':height,\n",
    "    'weight':weight,\n",
    "    'sex':sex\n",
    "})\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1　標本平均, 中央値, 最頻値\n",
    "\n",
    "まず、最もよく使われる統計量である、**標本平均**(mean)を定義します。\n",
    "\n",
    "$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$$\n",
    "\n",
    "$$\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i$$\n",
    "\n",
    "先の`sample_df`の標本平均を求めておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.groupby(['sex']).mean()    #男女別の平均をだす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて**中央値**(median)、これはデータをソートしたときに丁度中央にくる値のことです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(sample_df.height)    #データをsortした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.median()    #偶数個のときは、中央2つの平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[問題]　以下のスクリプトを参考に、標本平均と中央値の違いについて考察してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.asarray([0,0,0,0,0,0,100000])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean\", np.mean(d))\n",
    "print(\"median\", np.median(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**最頻値**(mode)は最も出てくる回数が多い値のことです。最頻値は一つの値に定まるとは限りません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.mode() #複数個の最頻値が取得できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 分散・標準偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分散**(variance)や**標準偏差**(standard deviation)は散らばり具合を表す統計量で、統計学において最も重要といっても過言ではない統計量です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[問題]　不偏分散の定義式を確認し、不偏分散を計算する関数を定義しなさい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[解答]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_var(x):\n",
    "    var = np.sum((x - np.mean(x))**2)/(len(x)-1)\n",
    "    return var\n",
    "\n",
    "print(\"体重の不偏分散\", my_var(sample_df.weight))\n",
    "print(\"体重の分散\", sample_df.weight.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "標準偏差を計算する場合は以下のようになります。\n",
    "\n",
    "* 標準偏差 = 分散の平方根\n",
    "\n",
    "平方根を取る理由は、変数の単位に注目するとわかります。身長を例にするなら分散の単位は$cm^2$、身長の標準偏差の単位は$cm$になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 分位点\n",
    "\n",
    "**四分位点**(quantile point)を導入します。四分位点とは、それより小さい値たちが全体の1/4, 2/4, 3/4となる点のことです。より一般に、n分位点とはそれより小さい値たちが全体の1/n, 2/n, ... , (n-1)/nとなる点のことをいいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#身長の四分位点\n",
    "sample_df.quantile(q = [0.25, 0.5, 0.75]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ソートした結果から四分位点がどのように計算されたか考えてみよう\n",
    "np.sort(sample_df.height) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[問題]　以下のデータの平均気温について、4分位点を求めてみなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_d = pd.read_csv(\"./data/weather.csv\", encoding = \"cp932\")\n",
    "weather_d.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[解答] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.quantile(q = [0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 tidyデータについて\n",
    "\n",
    "### 1.3.1 tidyデータとは\n",
    "\n",
    "`tidy`データ(2014～)という概念があります。これはデータ分析言語として`Python`言語と双璧をなす`R`言語において提唱された概念です。提唱者は`R`言語の神様として有名な **Hadley Wickham**です。`tidy`データとは、簡単に言えばすべての変数情報を列として持つデータのことをいいます。\n",
    "\n",
    "データがこの形式に整理されている利点は、特にデータ分析、機械学習を実行する際のコストのうち**前処理**と呼ばれるデータ成型のためのコストの面で非常に大きくなります。Wickhamは`tidy`データの概念を中心としたエコシステムを作り上げようとしています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./imgs/EPgIMLi.jpg\" width=200px></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "少し抽象的なので、例を見て考えてみよう。まず`tidy`でないデータから見てみることにしよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = np.array(['A', 'B', 'C', 'D', 'E'])\n",
    "a1 = np.array([150,160,175,130,155])\n",
    "a2 = np.array([100,130,150,90,130])\n",
    "\n",
    "bp_df = pd.DataFrame({\n",
    "    '患者':a0,\n",
    "    '投薬前血圧':a1,\n",
    "    '投薬後血圧':a2,\n",
    "})\n",
    "\n",
    "bp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さてこれを`tidy`データ化してみるとどうなるだろうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = np.array(['A', 'B', 'C', 'D', 'E','A', 'B', 'C', 'D', 'E'])\n",
    "a4 = np.array([150,160,175,130,155,100,130,150,90,130])\n",
    "a5 = np.array(['前', '後'])\n",
    "a6 = np.repeat(a5, [5,5], axis=0)\n",
    "\n",
    "tidybp_df = pd.DataFrame({\n",
    "    '患者':a3,\n",
    "    '血圧':a4,\n",
    "    '状態':a6\n",
    "})\n",
    "print(tidybp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tidy`データの意味が伝わったでしょうか。\n",
    "\n",
    "**tidyの条件**\n",
    "\n",
    "**・一つの変数に一つの列**\n",
    "\n",
    "**・一つの観測に一つの行**\n",
    "\n",
    "**・一つの表には一種類の観測**\n",
    "\n",
    "**・一つのセルには1つの値**\n",
    "\n",
    "`Python`や`R`では近年、このデータ形式に対してさまざな関数が対応するように設計されています。普段のデータ作成においても、`tidy`データを念頭において作成しておくとよいでしょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[問題]　以下の`tidy`でないデータを`tidy`データに直してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_notidy = pd.read_csv('./data/weather_notidy.csv', encoding='cp932')\n",
    "weather_notidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[解答]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = np.repeat(['札幌', '東京', '神戸'], 3)\n",
    "b2 = np.array(['6時', '12時', '18時']*3)\n",
    "b3 = np.array(['晴れ','晴れ','晴れ','曇り','雨','雨','雨','曇り','晴れ' ])\n",
    "\n",
    "tidyweather_df = pd.DataFrame({\n",
    "    '地点':b1,\n",
    "    '時刻':b2,\n",
    "    '天候':b3\n",
    "})\n",
    "print(tidyweather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 データの可視化\n",
    "\n",
    "ここではPythonを使って、**データの可視化**(data visualization)をする方法について学んでいきます。`matplotlib`や`seaborn`というライブラリが標準的に使われています。\n",
    "\n",
    "### 1.4.1 1変量データの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリなどの準備\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#表示桁数を調節する\n",
    "%precision 3\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib    # 日本語のトーフ化を避けるため\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#折れ線グラフ\n",
    "#正規分布に従う10個の乱数x,yの生成\n",
    "from numpy.random import randn\n",
    "x = randn(10)\n",
    "y = randn(10)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "#線グラフの描画\n",
    "plt.plot(x, color = \"orange\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.plot(y, color = \"blue\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"line plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "統計学的に大変重要なグラフである**ヒストグラム**(histogram)は以下のように作成できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正規乱数を100個生成\n",
    "from numpy.random import normal\n",
    "x = normal(loc=30,scale=10,size=100)\n",
    "\n",
    "#seabornでヒストグラム作成(kdeはカーネル密度推定)\n",
    "sns.displot(x,bins=range(0,100,10), kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#二項乱数を100個生成\n",
    "from numpy.random import binomial\n",
    "x = binomial(p = 0.3, n = 10,size=100)\n",
    "\n",
    "#seabornでヒストグラム作成\n",
    "sns.displot(x,bins = 5, kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**度数＝その値が何個出てきているか**\n",
    "\n",
    "**ヒストグラム＝度数を縦軸、横軸に観測された値のグラフ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[問題]　ヒストグラムをみるときに注目したいポイントについて考えてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[解答]\n",
    "\n",
    "ヒストグラムを見るときには、\n",
    "\n",
    "**1) 峰の数=山の頂点の個数（母集団の確率分布の種類を決める情報）**<br>\n",
    "**2) 全体の形状（=なだらかか、急か、どのくらい広がっているか→分散）**<br>\n",
    "**3) 変域（どこからどこまで数字が出ているか）, 幅（そのヒストグラムがどう作られたか）** \n",
    "\n",
    "について注目すると良いです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 多変量データの可視化\n",
    "次に多変量データの可視化、特に2変量の場合について考えよう。そのパターンとしては、\n",
    "\n",
    " **1) 量的変数×量的変数　→　散布図**\n",
    "\n",
    " **2) 量的変数×質的変数　→　箱ひげ図, バイオリンプロット**\n",
    "\n",
    " **3) 質的変数×質的変数　→　クロス集計表**\n",
    "\n",
    "があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.1 散布図\n",
    "\n",
    "まずは、量×量の場合の**散布図**(scatter plot)を書いてみましょう。\n",
    "ちなみに、以下に使用する`iris`データセットは非常に有名なデータセットであり、統計学では機械学習では頻繁に登場するので、どんなデータセットなのか覚えてしまうとよいでしょう。(ちなみに大統計学者Fisherのアヤメの分類のデータセットであり、歴史的な意義もあります。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#irisデータのダウンロードと確認\n",
    "iris = sns.load_dataset('iris')\n",
    "iris.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[問題]　`species`ごとに、各変数の平均値を求め、散布図をかいてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[解答]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris.groupby(\"species\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#散布図の作成(joint plot)\n",
    "sns.jointplot(x = iris.sepal_length, \n",
    "              y = iris.sepal_width, \n",
    "              data = iris)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris, hue = \"species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.2 箱ひげ図"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "量的変数×質的変数の可視化に便利なのが、**箱ひげ図**(boxplot)です。これは以下のようにかきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = \"species\", y = \"sepal_width\", data = iris)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.4.2.3 バイオリンプロット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最近、箱ひげ図の代わりに**バイオリンプロット**と呼ばれるものもよく使われるようになってきました。これにより、箱ひげ図とカーネル密度推定を同時に描画した図を得ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x = \"species\", y = \"sepal_width\", \n",
    "               data = iris, palette = \"colorblind\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.4 クロス集計表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "質的変数同士の関係を表すには、**クロス集計表**(cross table)にまとめるのが一般的です。ここでは、`tidy`データからクロス集計表を作成してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidyweather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tidyweather_dfを使ってクロス集計\n",
    "cross = pd.pivot_table(data=tidyweather_df,\n",
    "                       index='地点',\n",
    "                       columns='天候',\n",
    "                       aggfunc='count'\n",
    "                      )\n",
    "cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 相関係数\n",
    "\n",
    "2つの変数間になんらかの関係があるとき**相関**(correlation)があるといいます。相関という言葉は厳密には、2つの量的変数の線形な関係についてあてられるべき言葉ですが、ここではより広義に相関の意味をとっておきます。\n",
    "\n",
    "この場合も、可視化のときと同じく大分類として3通りになります。\n",
    "\n",
    " **1) 量的変数×量的変数　→　ピアソンの積率相関係数**\n",
    "\n",
    " **2) 量的変数×質的変数　→　相関比**\n",
    "\n",
    " **3) 質的変数×質的変数　→　クラメールの連関係数**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 相関係数(ピアソンの積率相関係数)\n",
    "\n",
    "まずは、量×量のときの**ピアソンの積率相関係数**(Pearson's correlation coefficient)についてここで見ておきましょう。この値は単に**相関係数**(correlation coefficient)とよぶことが多いです。\n",
    "\n",
    "$$Cor(x, y) = \\frac{Cov(x, y)}{sd(x)\\cdot sd(y)} = \\frac{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})(y - \\bar{y})}{\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x - \\bar{x})^2}\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y - \\bar{y})^2}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[問題]　上の式で定義された相関係数の分子の値を**共分散**(covariance)というが、この値が相関の強さを決定することを説明してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[解答]　共分散は、散布図上で点が左下と右下に多く集中しているときには、大きくなり。また、点が左上と右下に集中しているときには小さくなるから。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_d.drop(\"日\", axis = 1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 相関比\n",
    "質的変数と量的変数の関係の深さを表すには、**相関比**(correlation ratio)を用います。この値は、以下のように定義されます。\n",
    "\n",
    "$$ \\eta^2 = \\frac{S_B}{S_W + S_B}$$\n",
    "\n",
    "ここで、$S_B$は級間変動、$S_W$は級内変動と呼ばれる値です。以下のデータを用いて計算法を確認してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([400,500,600, 400,450,350, 500,600,700])\n",
    "y = np.repeat(['Kobe','Kagoshima','Osaka'], 3)\n",
    "\n",
    "salary_df = pd.DataFrame({\n",
    "    'salary' : x,\n",
    "    'place' : y\n",
    "})\n",
    "\n",
    "salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = \"place\", y = \"salary\", data = salary_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#全体平均の計算\n",
    "mu = salary_df.salary.mean()\n",
    "print('全体平均', mu)\n",
    "\n",
    "level_mu = np.repeat([500, 400, 600],3)\n",
    "print('水準平均', level_mu)\n",
    "\n",
    "#級間変動\n",
    "S_B = np.sum((level_mu - mu)**2)\n",
    "print('級間変動', S_B)\n",
    "\n",
    "#級内変動\n",
    "residuals = salary_df.salary - level_mu\n",
    "print('残差', residuals)\n",
    "S_W = np.sum(residuals**2)\n",
    "print('級内変動', S_W)\n",
    "\n",
    "#相関比\n",
    "eta2 = (S_B)/(S_B + S_W)\n",
    "print('相関比', eta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ちなみに、相関比の分母の$S_B + S_W$のことを**全体変動**$S_T$といいこの値は**偏差平方和**と一致します。すなわち\n",
    " \n",
    " $$偏差平方和 = 級間変動 + 級内変動$$\n",
    "\n",
    "が成立しています。これを**平方和分解**(decomposition of sum of squares)といい、統計学的にたいへん重要な概念です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[問題]　上記のことが本当に成り立っているか確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[解答]　以下を実行して偏差平方和を計算してみると、確かに級間変動と級内変動の和になっていることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#偏差平方和の計算\n",
    "np.sum((salary_df.salary - mu)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数学的に証明できる人は証明してみるのも面白いでしょう。幾何学的には三平方の定理として説明できたりもします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 クラメールの連関係数\n",
    "\n",
    "質的変数同士の場合は、クロス集計表に対して、**クラメールの連関係数**(Cramer's coefficient of association)$r_c$を計算することで、2つの質的変数の結びつきの強さを測定します。この値は以下の式で与えられます。\n",
    "\n",
    "$$r_c = \\sqrt{\\frac{\\chi^2}{n(k-1)}}$$\n",
    "\n",
    "ここで、$\\chi^2$を**カイ二乗値**(chi-square)と呼び。以下の式で定義します。\n",
    "\n",
    "$$\\chi^2 = \\sum \\frac{(観測度数 - 期待度数)^2}{期待度数}$$\n",
    "\n",
    "そのほか$n$は全データ数、$k$はクロス表の次元のうち小さい方の値です。以下のデータを用いて実際に計算してみよう。\n",
    "\n",
    "\n",
    "|科目\\専攻|数学専攻|それ以外|周辺度数|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|算数好き|30 |20|50|\n",
    "|国語好き|10 |60|70|\n",
    "|周辺度数|40|80|120|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#実測度数表\n",
    "sample_cross = np.array([[30,20],\n",
    "                         [10,60]])\n",
    "\n",
    "#期待度数表の作成\n",
    "ex_cross = np.array([[40 * 50/120, 80*50/120],\n",
    "                    [40 * 70/120, 80*70/120]])\n",
    "print(ex_cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[問題]　上記の計算をして求める期待度数とは何か答えてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[解答]　2つの質的変数に関係が全くなかった時に期待される度数のこと。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クラメール連関係数計算の続き\n",
    "chi_table = (sample_cross - ex_cross)**2/ex_cross\n",
    "print(chi_table)\n",
    "\n",
    "chisq = np.sum(chi_table)\n",
    "print('カイ二乗値', chisq)\n",
    "\n",
    "r_c = np.sqrt(chisq/(np.sum(sample_cross)*(min(sample_cross.shape)-1)))\n",
    "print('クラメールの連関係数', r_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "連関係数は0から１の値をとります。1に近いほど関係が強い、0に近いほど関係が弱いことを表します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
