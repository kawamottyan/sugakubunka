{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e51e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium\n",
    "#!pip install chromedriver-binary-auto\n",
    "#!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495f1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select,WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d21851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kawam\\AppData\\Local\\Temp\\ipykernel_33228\\3867760230.py:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function selenium.webdriver.support.expected_conditions.presence_of_all_elements_located.<locals>._predicate(driver)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#options = Options()\n",
    "#options.add_argument('--headless')    # ヘッドレスモードに\n",
    "#driver = webdriver.Chrome(options=options)\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "wait = WebDriverWait(driver,10)\n",
    "\n",
    "URL = \"https://db.netkeiba.com/?pid=race_search_detail\"\n",
    "driver.get(URL)\n",
    "time.sleep(1)\n",
    "wait.until(EC.presence_of_all_elements_located)\n",
    "\n",
    "#ダートの選択\n",
    "dart_element = driver.find_element(By.CSS_SELECTOR,\"#check_track_2\")\n",
    "dart_element.click()\n",
    "\n",
    "\n",
    "# 月ごとに検索\n",
    "year = 2019\n",
    "month = 1\n",
    "endyear = 2023\n",
    "endmonth = 1\n",
    "\n",
    "# 期間を選択\n",
    "#start_year_element = driver.find_element_by_name('start_year')\n",
    "start_year_element =driver.find_element(By.NAME,\"start_year\")\n",
    "start_year_select = Select(start_year_element)\n",
    "start_year_select.select_by_value(str(year))\n",
    "#start_mon_element = driver.find_element_by_name('start_mon')\n",
    "start_mon_element = driver.find_element(By.NAME,\"start_mon\")\n",
    "start_mon_select = Select(start_mon_element)\n",
    "start_mon_select.select_by_value(str(month))\n",
    "#end_year_element = driver.find_element_by_name('end_year')\n",
    "end_year_element = driver.find_element(By.NAME,\"end_year\")\n",
    "end_year_select = Select(end_year_element)\n",
    "end_year_select.select_by_value(str(endyear))\n",
    "#end_mon_element = driver.find_element_by_name('end_mon')\n",
    "end_mon_element = driver.find_element(By.NAME,\"end_mon\")\n",
    "end_mon_select = Select(end_mon_element)\n",
    "end_mon_select.select_by_value(str(endmonth))\n",
    "\n",
    "# 中央競馬場をチェック\n",
    "#for i in range(1,11):\n",
    "    #terms = driver.find_element_by_id(\"check_Jyo_\"+ str(i).zfill(2))\n",
    "#    terms = driver.find_element(By.ID,\"check_Jyo_\"+ str(i).zfill(2))\n",
    "#    terms.click()\n",
    "\n",
    "# 東京競馬場をチェック\n",
    "#tokyo_element = driver.find_element(By.CSS_SELECTOR,\"#check_Jyo_05\")\n",
    "tokyo_element = driver.find_element(By.ID,\"check_Jyo_\"+ str(5).zfill(2))\n",
    "tokyo_element.click()\n",
    "        \n",
    "# 表示件数を選択(20,50,100の中から最大の100へ)\n",
    "#list_element = driver.find_element_by_name('list')\n",
    "list_element = driver.find_element(By.NAME,\"list\")\n",
    "list_select = Select(list_element)\n",
    "list_select.select_by_value(\"100\")\n",
    "\n",
    "# フォームを送信\n",
    "#frm = driver.find_element_by_css_selector(\"#db_search_detail_form > form\")\n",
    "frm = driver.find_element(By.CSS_SELECTOR,\"#db_search_detail_form > form\")\n",
    "frm.submit()\n",
    "time.sleep(5)\n",
    "wait.until(EC.presence_of_all_elements_located)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd03d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(year)+\"-\"+str(month)+\".txt\", mode='w') as f:\n",
    "    while True:\n",
    "        time.sleep(5)\n",
    "        wait.until(EC.presence_of_all_elements_located)\n",
    "        #all_rows = driver.find_element_by_class_name('race_table_01').find_elements_by_tag_name(\"tr\")\n",
    "        all_rows = driver.find_element(By.CLASS_NAME,\"race_table_01\").find_elements(By.TAG_NAME,\"tr\")\n",
    "        for row in range(1, len(all_rows)):\n",
    "            #race_href=all_rows[row].find_elements_by_tag_name(\"td\")[4].find_element_by_tag_name(\"a\").get_attribute(\"href\")\n",
    "            race_href=all_rows[row].find_elements(By.TAG_NAME,\"td\")[4].find_element(By.TAG_NAME,\"a\").get_attribute(\"href\")\n",
    "            f.write(race_href+\"\\n\")\n",
    "        try:\n",
    "            #target = driver.find_elements_by_link_text(\"次\")[0]\n",
    "            target = driver.find_elements(By.LINK_TEXT,\"次\")[0]\n",
    "            driver.execute_script(\"arguments[0].click();\", target) #javascriptでクリック処理\n",
    "        except IndexError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf27301",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2019-1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(save_dir):\n\u001b[0;32m      3\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(save_dir)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmonth\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m     urls \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2019-1.txt'"
     ]
    }
   ],
   "source": [
    "save_dir = \"html\"+\"/\"+str(year)+\"/\"+str(month)\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "        \n",
    "with open(str(year)+\"-\"+str(month)+\".txt\", \"r\") as f:\n",
    "    urls = f.read().splitlines()\n",
    "    for url in urls:\n",
    "        list = url.split(\"/\")\n",
    "        race_id = list[-2]\n",
    "        save_file_path = save_dir+\"/\"+race_id+'.html'\n",
    "        response = requests.get(url)\n",
    "        response.encoding = response.apparent_encoding\n",
    "        html = response.text\n",
    "        time.sleep(5)\n",
    "        with open(save_file_path, 'w') as file:\n",
    "            file.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e28a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_data_columns=[\n",
    "    'race_id',\n",
    "    'race_round',\n",
    "    'race_title',\n",
    "    'race_course',\n",
    "    'weather',\n",
    "    'ground_status',\n",
    "    'time',\n",
    "    'date',\n",
    "    'where_racecourse',\n",
    "    'total_horse_number',\n",
    "    'frame_number_first',\n",
    "    'horse_number_first',\n",
    "    'frame_number_second',\n",
    "    'horse_number_second',\n",
    "    'frame_number_third',\n",
    "    'horse_number_third',\n",
    "    'tansyo',\n",
    "    'hukusyo_first',\n",
    "    'hukusyo_second',\n",
    "    'hukusyo_third',\n",
    "    'wakuren',\n",
    "    'umaren',\n",
    "    'wide_1_2',\n",
    "    'wide_1_3',\n",
    "    'wide_2_3',\n",
    "    'umatan',\n",
    "    'renhuku3',\n",
    "    'rentan3'\n",
    "    ]\n",
    "\n",
    "horse_data_columns=[\n",
    "    'race_id',\n",
    "    'rank',\n",
    "    'frame_number',\n",
    "    'horse_number',\n",
    "    'horse_id',\n",
    "    'sex_and_age',\n",
    "    'burden_weight',\n",
    "    'rider_id',\n",
    "    'goal_time',\n",
    "    'goal_time_dif',\n",
    "    'time_value',\n",
    "    'half_way_rank',\n",
    "    'last_time',\n",
    "    'odds',\n",
    "    'popular',\n",
    "    'horse_weight',\n",
    "    'tame_time',\n",
    "    'tamer_id',\n",
    "    'owner_id'\n",
    "]\n",
    "\n",
    "\n",
    "def get_rade_and_horse_data_by_html(race_id, html):\n",
    "    race_list = [race_id]\n",
    "    horse_list_list = []\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # race基本情報\n",
    "    data_intro = soup.find(\"div\", class_=\"data_intro\")\n",
    "    race_list.append(data_intro.find(\"dt\").get_text().strip(\"\\n\")) # race_round\n",
    "    race_list.append(data_intro.find(\"h1\").get_text().strip(\"\\n\")) # race_title\n",
    "    race_details1 = data_intro.find(\"p\").get_text().strip(\"\\n\").split(\"\\xa0/\\xa0\")\n",
    "    race_list.append(race_details1[0]) # race_course\n",
    "    race_list.append(race_details1[1]) # weather\n",
    "    race_list.append(race_details1[2]) # ground_status\n",
    "    race_list.append(race_details1[3]) # time\n",
    "    race_details2 = data_intro.find(\"p\", class_=\"smalltxt\").get_text().strip(\"\\n\").split(\" \")\n",
    "    race_list.append(race_details2[0]) # date\n",
    "    race_list.append(race_details2[1]) # where_racecourse\n",
    "\n",
    "\n",
    "    result_rows = soup.find(\"table\", class_=\"race_table_01 nk_tb_common\").findAll('tr') # レース結果\n",
    "    # 上位3着の情報\n",
    "    race_list.append(len(result_rows)-1) # total_horse_number\n",
    "    for i in range(1,4):\n",
    "        row = result_rows[i].findAll('td')\n",
    "        race_list.append(row[1].get_text()) # frame_number_first or second or third\n",
    "        race_list.append(row[2].get_text()) # horse_number_first or second or third\n",
    "\n",
    "\n",
    "    # 払い戻し(単勝・複勝・三連複・3連単)\n",
    "    pay_back_tables = soup.findAll(\"table\", class_=\"pay_table_01\")\n",
    "\n",
    "    pay_back1 = pay_back_tables[0].findAll('tr') # 払い戻し1(単勝・複勝)\n",
    "    race_list.append(pay_back1[0].find(\"td\", class_=\"txt_r\").get_text()) #tansyo\n",
    "    hukuren = pay_back1[1].find(\"td\", class_=\"txt_r\")\n",
    "    tmp = []\n",
    "    for string in hukuren.strings:\n",
    "        tmp.append(string)\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            race_list.append(tmp[i]) # hukuren_first or second or third\n",
    "        except IndexError:\n",
    "            race_list.append(\"0\")\n",
    "\n",
    "    # 枠連\n",
    "    try:\n",
    "        race_list.append(pay_back1[2].find(\"td\", class_=\"txt_r\").get_text())\n",
    "    except IndexError:\n",
    "        race_list.append(\"0\")\n",
    "\n",
    "    # 馬連\n",
    "    try:\n",
    "        race_list.append(pay_back1[3].find(\"td\", class_=\"txt_r\").get_text())\n",
    "    except IndexError:\n",
    "        race_list.append(\"0\")\n",
    "\n",
    "\n",
    "\n",
    "    pay_back2 = pay_back_tables[1].findAll('tr') # 払い戻し2(三連複・3連単)\n",
    "\n",
    "    # wide 1&2\n",
    "    wide = pay_back2[0].find(\"td\", class_=\"txt_r\")\n",
    "    tmp = []\n",
    "    for string in wide.strings:\n",
    "        tmp.append(string)\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            race_list.append(tmp[i]) # hukuren_first or second or third\n",
    "        except IndexError:\n",
    "            race_list.append(\"0\")\n",
    "\n",
    "    # umatan\n",
    "    race_list.append(pay_back2[1].find(\"td\", class_=\"txt_r\").get_text()) #umatan\n",
    "\n",
    "    race_list.append(pay_back2[2].find(\"td\", class_=\"txt_r\").get_text()) #renhuku3\n",
    "    try:\n",
    "        race_list.append(pay_back2[3].find(\"td\", class_=\"txt_r\").get_text()) #rentan3\n",
    "    except IndexError:\n",
    "        race_list.append(\"0\")\n",
    "\n",
    "    # horse data\n",
    "    for rank in range(1, len(result_rows)):\n",
    "        horse_list = [race_id]\n",
    "        result_row = result_rows[rank].findAll(\"td\")\n",
    "        # rank\n",
    "        horse_list.append(result_row[0].get_text())\n",
    "        # frame_number\n",
    "        horse_list.append(result_row[1].get_text())\n",
    "        # horse_number\n",
    "        horse_list.append(result_row[2].get_text())\n",
    "        # horse_id\n",
    "        horse_list.append(result_row[3].find('a').get('href').split(\"/\")[-2])\n",
    "        # sex_and_age\n",
    "        horse_list.append(result_row[4].get_text())\n",
    "        # burden_weight\n",
    "        horse_list.append(result_row[5].get_text())\n",
    "        # rider_id\n",
    "        horse_list.append(result_row[6].find('a').get('href').split(\"/\")[-2])\n",
    "        # goal_time\n",
    "        horse_list.append(result_row[7].get_text())\n",
    "        # goal_time_dif\n",
    "        horse_list.append(result_row[8].get_text())\n",
    "        # time_value(premium)\n",
    "        horse_list.append(result_row[9].get_text())\n",
    "        # half_way_rank\n",
    "        horse_list.append(result_row[10].get_text())\n",
    "        # last_time(上り)\n",
    "        horse_list.append(result_row[11].get_text())\n",
    "        # odds\n",
    "        horse_list.append(result_row[12].get_text())\n",
    "        # popular\n",
    "        horse_list.append(result_row[13].get_text())\n",
    "        # horse_weight\n",
    "        horse_list.append(result_row[14].get_text())\n",
    "        # tame_time(premium)\n",
    "        horse_list.append(result_row[15].get_text())\n",
    "        # 16:コメント、17:備考\n",
    "        # tamer_id\n",
    "        horse_list.append(result_row[18].find('a').get('href').split(\"/\")[-2])\n",
    "        # owner_id\n",
    "        horse_list.append(result_row[19].find('a').get('href').split(\"/\")[-2])\n",
    "\n",
    "        horse_list_list.append(horse_list)\n",
    "\n",
    "    return race_list, horse_list_list\n",
    "\n",
    "CSV_DIR = \"csv\"\n",
    "if not os.path.isdir(CSV_DIR):\n",
    "    os.makedirs(CSV_DIR)\n",
    "save_race_csv = CSV_DIR+\"/race-\"+str(year)+\"-\"+str(month)+\".csv\"\n",
    "horse_race_csv = CSV_DIR+\"/horse-\"+str(year)+\"-\"+str(month)+\".csv\"\n",
    "\n",
    "# race_data_columns, horse_data_columnsは長くなるので省略\n",
    "race_df = pd.DataFrame(columns=race_data_columns )\n",
    "horse_df = pd.DataFrame(columns=horse_data_columns )\n",
    "\n",
    "html_dir = \"html\"+\"/\"+str(year)+\"/\"+str(month)\n",
    "if os.path.isdir(html_dir):\n",
    "    file_list = os.listdir(html_dir)\n",
    "    for file_name in file_list:\n",
    "        with open(html_dir+\"/\"+file_name, \"r\") as f:\n",
    "            html = f.read()\n",
    "            list = file_name.split(\".\")\n",
    "            race_id = list[-2]\n",
    "            race_list, horse_list_list = get_rade_and_horse_data_by_html(race_id, html) # 長くなるので省略\n",
    "            for horse_list in horse_list_list:\n",
    "                horse_se = pd.Series( horse_list, index=horse_df.columns)\n",
    "                horse_df = horse_df.append(horse_se, ignore_index=True)\n",
    "            race_se = pd.Series(race_list, index=race_df.columns )\n",
    "            race_df = race_df.append(race_se, ignore_index=True )\n",
    "            \n",
    "race_df.to_csv(save_race_csv, header=True, index=False)\n",
    "horse_df.to_csv(horse_race_csv, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbeb082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 時間情報を抜き出して、日付情報と結合。datetime型にする\n",
    "race_df[\"time\"] = race_df[\"time\"].str.replace('発走 : (\\d\\d):(\\d\\d)(.|\\n)*', r'\\1時\\2分')\n",
    "race_df[\"date\"] = race_df[\"date\"] + race_df[\"time\"]\n",
    "race_df[\"date\"] = pd.to_datetime(race_df['date'], format='%Y年%m月%d日%H時%M分')\n",
    "# もともとのtimeは不要なので削除\n",
    "race_df.drop(['time'], axis=1, inplace=True)\n",
    "\n",
    "# 何ラウンド目かのカラムに余分なRや空白・改行が含まれているので取り除く\n",
    "race_df['race_round'] = race_df['race_round'].str.strip('R \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be66bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
